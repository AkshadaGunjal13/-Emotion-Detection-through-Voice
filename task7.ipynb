{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMUVbZ0lisJf1IohrbBrXIB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"c13tsuVe945S","executionInfo":{"status":"ok","timestamp":1748892042741,"user_tz":-330,"elapsed":12570,"user":{"displayName":"Akshada Gunjal","userId":"17152451300241560849"}},"outputId":"56e02f79-2c3e-468a-a04d-f12a461273a1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gradio==3.50.2 in /usr/local/lib/python3.11/dist-packages (3.50.2)\n","Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.11.0)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n","Requirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (0.13.1)\n","Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (0.25.1)\n","Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2) (23.2.1)\n","Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2) (5.5.0)\n","Requirement already satisfied: fastapi in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2) (0.115.12)\n","Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2) (0.6.0)\n","Requirement already satisfied: gradio-client==0.6.1 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2) (0.6.1)\n","Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2) (0.28.1)\n","Requirement already satisfied: huggingface-hub>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2) (0.31.4)\n","Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2) (6.5.2)\n","Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2) (3.1.6)\n","Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2) (2.1.5)\n","Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2) (3.10.0)\n","Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2) (1.26.4)\n","Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2) (3.10.18)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2) (24.2)\n","Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2) (2.2.2)\n","Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2) (10.4.0)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2) (2.11.4)\n","Requirement already satisfied: python-multipart in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2) (0.0.20)\n","Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2) (6.0.2)\n","Requirement already satisfied: requests~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2) (2.32.3)\n","Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2) (2.10.0)\n","Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2) (4.13.2)\n","Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2) (0.34.3)\n","Requirement already satisfied: websockets<12.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2) (11.0.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==0.6.1->gradio==3.50.2) (2025.3.2)\n","Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n","Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.15.3)\n","Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.5.0)\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\n","Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n","Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n","Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n","Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n","Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n","Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n","Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n","Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile) (1.17.1)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6.0,>=4.2.0->gradio==3.50.2) (4.23.0)\n","Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6.0,>=4.2.0->gradio==3.50.2) (1.40.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile) (2.22)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.14.0->gradio==3.50.2) (3.18.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.14.0->gradio==3.50.2) (4.67.1)\n","Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n","Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio==3.50.2) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio==3.50.2) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio==3.50.2) (4.58.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio==3.50.2) (1.4.8)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio==3.50.2) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio==3.50.2) (2.9.0.post0)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio==3.50.2) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio==3.50.2) (2025.2)\n","Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.8)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio==3.50.2) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio==3.50.2) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio==3.50.2) (0.4.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests~=2.0->gradio==3.50.2) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests~=2.0->gradio==3.50.2) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests~=2.0->gradio==3.50.2) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests~=2.0->gradio==3.50.2) (2025.4.26)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn>=0.14.0->gradio==3.50.2) (8.2.1)\n","Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn>=0.14.0->gradio==3.50.2) (0.16.0)\n","Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi->gradio==3.50.2) (0.46.2)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->gradio==3.50.2) (4.9.0)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->gradio==3.50.2) (1.0.9)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50.2) (25.3.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50.2) (2025.4.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50.2) (0.36.2)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50.2) (0.25.1)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx->gradio==3.50.2) (1.3.1)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","IMPORTANT: You are using gradio version 3.50.2, however version 4.44.1 is available, please upgrade.\n","--------\n","Running on public URL: https://e8762c8b238a86f10d.gradio.live\n","\n","This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div><iframe src=\"https://e8762c8b238a86f10d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"]},"metadata":{}}],"source":["# Install required packages\n","!pip install gradio==3.50.2 librosa tensorflow scikit-learn soundfile pydub\n","\n","import numpy as np\n","import librosa\n","import gradio as gr\n","import tempfile\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, Activation\n","\n","# Constants\n","SAMPLE_RATE = 22050\n","DURATION = 3  # seconds\n","EMOTIONS = ['neutral', 'happy', 'sad', 'angry', 'fear', 'disgust', 'surprise']\n","GENDER_LABELS = ['female', 'male']\n","\n","# Enhanced feature extraction\n","def extract_features(audio_data, sr=SAMPLE_RATE):\n","    try:\n","        # MFCC features with more robust extraction\n","        mfccs = librosa.feature.mfcc(\n","            y=audio_data,\n","            sr=sr,\n","            n_mfcc=13,\n","            n_fft=2048,\n","            hop_length=512\n","        )\n","        mfccs_mean = np.mean(mfccs.T, axis=0)\n","\n","        # Add pitch and harmonic features for better gender detection\n","        pitch = librosa.yin(audio_data, fmin=80, fmax=400, sr=sr)\n","        pitch_mean = np.mean(pitch)\n","\n","        return np.append(mfccs_mean, pitch_mean)\n","    except Exception as e:\n","        print(f\"Feature extraction error: {e}\")\n","        return None\n","\n","# Improved mock gender model\n","def create_gender_model(input_shape):\n","    model = Sequential([\n","        Dense(128, input_shape=(input_shape,), activation='relu'),\n","        Dropout(0.4),\n","        Dense(64, activation='relu'),\n","        Dropout(0.3),\n","        Dense(len(GENDER_LABELS), activation='softmax')\n","    ])\n","    model.compile(\n","        loss='categorical_crossentropy',\n","        optimizer='adam',\n","        metrics=['accuracy']\n","    )\n","    return model\n","\n","# Emotion model\n","def create_emotion_model(input_shape):\n","    model = Sequential([\n","        Dense(256, input_shape=(input_shape,), activation='relu'),\n","        Dropout(0.5),\n","        Dense(128, activation='relu'),\n","        Dropout(0.4),\n","        Dense(len(EMOTIONS), activation='softmax')\n","    ])\n","    model.compile(\n","        loss='categorical_crossentropy',\n","        optimizer='adam',\n","        metrics=['accuracy']\n","    )\n","    return model\n","\n","# Initialize models with proper feature size (14 = 13 MFCC + pitch)\n","gender_model = create_gender_model(14)\n","emotion_model = create_emotion_model(14)\n","\n","# Adjust gender detection threshold (higher means more strict female detection)\n","FEMALE_THRESHOLD = 0.7  # 70% confidence\n","\n","def predict_emotion(audio_input):\n","    try:\n","        # Handle both file upload and recording\n","        if isinstance(audio_input, str):\n","            # File upload\n","            audio_data, sr = librosa.load(audio_input, sr=SAMPLE_RATE)\n","        else:\n","            # Recording - need to handle differently for Colab\n","            sr, audio_data = audio_input\n","            if len(audio_data.shape) > 1:  # Convert stereo to mono\n","                audio_data = librosa.to_mono(audio_data)\n","\n","            # Save temporary file for librosa processing\n","            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tmp:\n","                tmp_path = tmp.name\n","                librosa.output.write_wav(tmp_path, audio_data, sr)\n","\n","            audio_data, sr = librosa.load(tmp_path, sr=SAMPLE_RATE)\n","\n","        # Process audio\n","        audio_data = librosa.resample(audio_data, orig_sr=sr, target_sr=SAMPLE_RATE)\n","        if len(audio_data) > SAMPLE_RATE * DURATION:\n","            audio_data = audio_data[:SAMPLE_RATE * DURATION]\n","        else:\n","            padding = SAMPLE_RATE * DURATION - len(audio_data)\n","            audio_data = np.pad(audio_data, (0, padding), mode='constant')\n","\n","        # Extract features\n","        features = extract_features(audio_data)\n","        if features is None or len(features) != 14:\n","            return \"Error: Could not extract proper audio features\"\n","\n","        # Predict gender with confidence\n","        gender_pred = gender_model.predict(features.reshape(1, -1))\n","        gender_idx = np.argmax(gender_pred)\n","        gender_confidence = gender_pred[0][gender_idx]\n","        gender = GENDER_LABELS[gender_idx]\n","\n","        # Only reject if confidence is high it's male\n","        if gender == 'male' and gender_confidence > (1 - FEMALE_THRESHOLD):\n","            return f\"Please upload female voice (detected {gender} with {gender_confidence:.1%} confidence)\"\n","        elif gender == 'female' and gender_confidence < FEMALE_THRESHOLD:\n","            return \"Voice gender unclear - please try again with clearer female voice\"\n","\n","        # Predict emotion\n","        emotion_pred = emotion_model.predict(features.reshape(1, -1))\n","        emotion_idx = np.argmax(emotion_pred)\n","        emotion = EMOTIONS[emotion_idx]\n","        confidence = emotion_pred[0][emotion_idx]\n","\n","        return f\"Detected emotion: {emotion} ({confidence:.1%} confidence)\"\n","\n","    except Exception as e:\n","        return f\"Error processing audio: {str(e)}\"\n","\n","# Create Gradio interface with Colab-compatible settings\n","def create_interface():\n","    with gr.Blocks(title=\"Female Voice Emotion Detection\") as interface:\n","        gr.Markdown(\"## Female Voice Emotion Detection\")\n","        gr.Markdown(\"Please speak clearly for 3-5 seconds\")\n","\n","        with gr.Tab(\"Upload Audio File\"):\n","            gr.Markdown(\"Upload a recorded voice note (WAV format preferred)\")\n","            file_input = gr.Audio(type=\"filepath\", label=\"Audio File\")\n","            file_output = gr.Textbox(label=\"Analysis Result\")\n","            file_button = gr.Button(\"Analyze Upload\")\n","\n","        with gr.Tab(\"Record Voice\"):\n","            gr.Markdown(\"Record directly from your microphone\")\n","            gr.Markdown(\"Note: In Colab, you need to click 'Allow' when prompted for microphone access\")\n","            record_input = gr.Audio(source=\"microphone\", type=\"numpy\", label=\"Recording\")\n","            record_output = gr.Textbox(label=\"Analysis Result\")\n","            record_button = gr.Button(\"Analyze Recording\")\n","\n","        file_button.click(predict_emotion, inputs=file_input, outputs=file_output)\n","        record_button.click(predict_emotion, inputs=record_input, outputs=record_output)\n","\n","    return interface\n","\n","# Launch the interface\n","if __name__ == \"__main__\":\n","    interface = create_interface()\n","    try:\n","        # Try launching with share=True first\n","        interface.launch(share=True)\n","    except Exception as e:\n","        print(\"Failed to launch with share=True, trying without sharing...\")\n","        interface.launch()"]}]}